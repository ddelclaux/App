{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a678a9e6-094b-40c5-9ffa-a3bf783d84ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app5.py\n",
    "\n",
    "import streamlit as st\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "# Crea la interfaz de usuario con Streamlit\n",
    "st.sidebar.title(\"Opciones\")\n",
    "opcion = st.sidebar.selectbox(\"Elige un modelo\", [\"Resumir\", \"Q & A\"])\n",
    "\n",
    "\n",
    "#Bienvenidos a la App\n",
    "if opcion == \"Resumir\":\n",
    "    st.title('Resumir')\n",
    "    texto = st.text_area('Ingrese el texto a resumir', 'Escriba aquí el texto')\n",
    "    longitud_resumen = st.slider('Seleccione la longitud del resumen', min_value=1, max_value=500, value=10)\n",
    "    summarizer = pipeline('summarization', model='facebook/bart-large-cnn', tokenizer='facebook/bart-large-cnn')\n",
    "    if st.button('Generar Resumen'):\n",
    "        resumen = summarizer(texto, max_length=longitud_resumen)\n",
    "        st.success('Aquí está el resumen:')\n",
    "        st.write(resumen[0]['summary_text'])\n",
    "    \n",
    "\n",
    "# Create the pipeline\n",
    "q_and_a = pipeline('question-answering')\n",
    "\n",
    "if opcion == \"Q & A\":\n",
    "    st.title('Q & A')\n",
    "    text_input = st.text_area(\"Please enter the text:\")\n",
    "    question_input = st.text_input(\"Please enter the question:\")\n",
    "    if st.button(\"Ask the model\"):\n",
    "        answer = q_and_a(context=text_input, question=question_input)\n",
    "        st.write(\"Answer: \", answer['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223f56cf-876e-4176-9f33-3f0f87677c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.1.44:8501\u001b[0m\n",
      "\u001b[0m\n",
      "2022-12-23 20:25:46.575070: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-cnn.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n",
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "2022-12-23 20:25:59.361033: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "Some layers from the model checkpoint at distilbert-base-cased-distilled-squad were not used when initializing TFDistilBertForQuestionAnswering: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased-distilled-squad and are newly initialized: ['dropout_105']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All model checkpoint layers were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFDistilBertForQuestionAnswering were initialized from the model checkpoint at distilbert-base-cased-distilled-squad.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app5.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
